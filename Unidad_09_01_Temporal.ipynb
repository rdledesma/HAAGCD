{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducci√≥n a las series temporales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesar correctamente diferentes tipos de datos requiere de transformaciones matem√°ticas concretas\n",
    "(por ejemplo, transformar una caracter√≠stica categ√≥rica en one-hot-encoding) o estructuras de redes especiales (por ejemplo, redes convolucionales para procesar im√°genes) para poder tener en cuenta aquellas caracter√≠sticas concretas que tienen esas estructuras de datos. De forma an√°loga, parece interesante pensar que un estudio acerca de qu√© son los datos de naturaleza secuencial puede llevar a proporcionar la intuici√≥n sobre la forma en que se deber√≠a estructurar una red que sea capaz de\n",
    "extraer informaci√≥n de este tipo de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu√≠ hay que partir de lo que se considera una serie temporal; cualquier dato que haya sido recogido en intervalos de tiempo constituye una serie temporal. Es un conjunto de observaciones donde la relaci√≥n de obtenci√≥n de cada punto importa y puede aportar mucha informaci√≥n del fen√≥meno\n",
    "que se intenta resolver. Cambiar su orden cambiar√≠a el significado de los datos y, por tanto, ser√≠a una fuente de ruido para los modelos. Un ejemplo de serie temporal puede ser el ejemplo que se muestra a continuaci√≥n: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de serie temporal, coches vendidos por mes en un concesionario, entre enero de\n",
    "2018 y enero de 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/sales.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, hay una variable dependiente del tiempo que va desde enero de 2018 hasta diciembre de 2020 con frecuencia mensual. Para cada mes, se tiene el n√∫mero de coches vendidos y hay, por tanto, un total de 36 valores en la serie temporal. \n",
    "\n",
    "El ejemplo es un caso de serie temporal univariante. Si hubiera m√∫ltiples variables\n",
    "dependientes del tiempo (por ejemplo, las ventas de coches en los concesionarios de\n",
    "la ciudad) se estar√≠a hablando de serie temporal multivariante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/sales-multivariante.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El an√°lisis de series temporales tiene una enorme aplicabilidad en m√∫ltiples disciplinas cient√≠ficas:\n",
    "\n",
    "- **Econom√≠a**: an√°lisis de precios y demandas.\n",
    "- **Marketing**: seguimiento de ventas y evoluci√≥n de productos.\n",
    "- **Medicina**: an√°lisis de biose√±ales (ECG, EEG, EOG) y datos cl√≠nicos como:\n",
    "  - N√∫mero de pacientes en urgencias.\n",
    "  - Demanda de especialistas.\n",
    "  - Llamadas a servicios de emergencia (112).\n",
    "\n",
    "- **Meteorolog√≠a/Climatolog√≠a**: an√°lisis y predicci√≥n de fen√≥menos clim√°ticos, especialmente relevantes por el cambio clim√°tico.\n",
    "- **IoT (Internet of Things)**: an√°lisis de datos capturados por sensores en procesos, personas o dispositivos.\n",
    "\n",
    "## Series Temporales y Datos Secuenciales\n",
    "\n",
    "M√°s all√° de las series temporales cl√°sicas, existen datos secuenciales que tambi√©n pueden ser tratados con t√©cnicas similares:\n",
    "\n",
    "- **Lenguaje natural (NLP)**:\n",
    "  - Predicci√≥n de palabras.\n",
    "  - Resumen y traducci√≥n de textos.\n",
    "  - Generaci√≥n de im√°genes a partir de texto.\n",
    "\n",
    "- **Sonido**:\n",
    "  - Identificaci√≥n de g√©nero musical.\n",
    "  - Comparaci√≥n entre canciones.\n",
    "  - Transcripci√≥n de voz a texto.\n",
    "  - Generaci√≥n de im√°genes desde sonido.\n",
    "\n",
    "> Se recomienda consultar bibliograf√≠a especializada en NLP para un tratamiento m√°s profundo de estos temas.\n",
    "\n",
    "## Preprocesamiento de Datos\n",
    "\n",
    "El √©xito de un modelo de aprendizaje profundo depende en gran medida del procesamiento adecuado de los datos. Para ello, es esencial comprender propiedades clave de las series temporales como:\n",
    "\n",
    "- **Tendencia**\n",
    "- **Estacionalidad**\n",
    "- **Estacionariedad**\n",
    "\n",
    "Estas propiedades ser√°n introducidas en este cap√≠tulo para mejorar la preparaci√≥n de datos antes del modelado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tendencia: Es un comportamiento que muestra el desplazamiento lineal de los valores de la serie temporal sobre un gran periodo de tiempo. Dicho de otra forma, se observa una tendencia cuando hay un comportamiento lineal que puede tener una pendiente positiva o negativa dentro de la serie\n",
    "temporal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/tendencia.png\" alt=\"Total de coches vendidos\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tendencia no tiene por qu√© ser constante en una serie temporal: puede cambiar de creciente a decreciente, o puede incluso cambiar su pendiente seg√∫n va avanzando el tiempo. Existe incluso la posibilidad de que no aparezca una tendencia clara en la serie temporal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_t = \\frac{1}{N} \\sum_{k=0}^{N-1} X_{t-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La media m√≥vil permite eliminar peque√±as oscilaciones obteniendo la tendencia de la serie temporal en cada punto. La serie temporal obtenida es menos sensible a las vibraciones de alta frecuencia, centr√°ndose en los comportamientos a largo plazo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/media.png\" alt=\"Total de coches vendidos\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El c√°lculo de la media m√≥vil depende del par√°metro N; este par√°metro determina las frecuencias de las oscilaciones de alta frecuencia que son eliminadas/amortiguadas. Se puede demostrar que esta operaci√≥n de promediado act√∫a como un filtro pasa-baja, sistema que deja pasar las bajas frecuencias y elimina las altas. A mayor valor de N, m√°s datos se cogen para el c√°lculo de la media y una mayor cantidad de altas frecuencias son eliminadas. En la pr√°ctica, es interesante escoger un valor de N que permita eliminar el ruido a corto plazo, pero no tan grande como para obviar los movimientos de la tendencia que, precisamente, se quieren obtener con la media m√≥vil; aqu√≠ el conocimiento del experto en\n",
    "el problema es fundamental."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/medias.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estacionalidad. Es una caracter√≠stica de las series temporales en la que los datos experimentan cambios regulares y predecibles con una frecuencia constante. Esta frecuencia puede ser, por ejemplo, diaria, semanal o mensual.\n",
    "\n",
    "Cualquier fluctuaci√≥n predecible de frecuencia constante que aparezca en una serie temporal se dice que es estacional. \n",
    "\n",
    "Aparece de forma natural en muchos procesos medidos. El consumo el√©ctrico en una casa presenta una frecuencia estacional diaria (cuando estamos durmiendo, no se consume electricidad, por ejemplo). Adem√°s, el consumo el√©ctrico crece en las √©pocas fr√≠as como oto√±o e invierno, por lo que se aprecia tambi√©n una estacionalidad de frecuencia anual. Otro ejemplo son las ventas de productos por internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/estacionalidad.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la figura (A), se puede observar que la gente tiende a comprar m√°s productos en las cercan√≠as del fin de semana: se puede apreciar gr√°ficamente la estacionalidad semanal. En la figura (B) se representa la misma cantidad que en la gr√°fica superior, pero en un intervalo temporal anterior. Este intervalo temporal coincidi√≥ con una campa√±a de marketing agresiva que populariz√≥ la tienda e hizo que las ventas crecieran mucho. Las dos series temporales presentan la misma estacionalidad, a pesar de que sus valores m√°ximos y m√≠nimos en distintos puntos sean tan distintos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los m√©todos utilizados com√∫nmente para cuantificar esta estacionalidad de forma matem√°tica es usar la operaci√≥n de diferenciaci√≥n. Consiste en obtener una nueva serie temporal a partir de la original calculando diferencias de valores en diferentes instantes de tiempo. La diferenciaci√≥n\n",
    "de primer orden de una serie temporal ser√≠a la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X^1_t = X_t - X_{t-1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la nueva serie temporal diferenciada tendr√≠a una entrada menos que la serie temporal original. La diferenciaci√≥n necesaria para eliminar la tendencia estacional es la diferenciaci√≥n estacional. Se calcula aplicando la diferencia entre la observaci√≥n y la observaci√≥n anterior en\n",
    "la misma posici√≥n de la estaci√≥n. Por ejemplo, en el ejemplo descrito anteriormente, la diferencia estacional del d√≠a jueves 28/02 se calcular√≠a restando el valor original del jueves 28/02 con el valor del jueves anterior, 21/02, expresado matem√°ticamente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X^1_t = X_t - X_{t-p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde pes el periodo estacional, en el ejemplo descrito anteriormente,p = 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/desestacional.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estacionariedad. Una serie temporal es estacionaria si su media y su desviaci√≥n est√°ndar se mantienen constantes en el tiempo. Gr√°ficamente, esto se puede apreciar cuando los valores de la serie oscilan alrededor de una media constante y la variabilidad con respecto a esa media\n",
    "tambi√©n permanece constante en el tiempo. Las series que presenten una tendencia o una estacionalidad no son estacionarias, pero se pueden utilizar los m√©todos descritos anteriormente para intentar transformar una serie en estacionaria. Existe la posibilidad de que simplemente con estos\n",
    "m√©todos no se pueda transformar la serie en estacionaria y haga falta\n",
    "echar mano de otros m√©todos,(que sucede con las redes recurrentes aqu√≠??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez vistas las caracter√≠sticas b√°sicas de una serie temporal, haremos un r√°pido repaso a los m√©todos cl√°sicos antes de explicar los basados en Aprendizaje Profundo.\n",
    "\n",
    "Existe un gran n√∫mero de modelos utilizados para modelizar y realizar predicciones en series temporales. Estos modelos tienen como caracter√≠stica general su **linealidad**, es decir, presentan dependencia lineal con errores pasados y/o con valores anteriores de la serie.\n",
    "\n",
    "### Tipos de modelos cl√°sicos\n",
    "\n",
    "- **MA (Moving Average)**: modelos que consideran los errores pasados.\n",
    "- **AR (Autoregressive)**: modelos que consideran valores anteriores de la serie.\n",
    "- **ARMA**: combinaci√≥n de AR y MA.  \n",
    "  Son modelos **flexibles**, ya que el n√∫mero de entradas/salidas se puede ajustar seg√∫n el problema.\n",
    "\n",
    "Los **par√°metros**, principalmente el orden del modelo, se pueden estimar mediante la **autocorrelaci√≥n** y la **correlaci√≥n parcial** de la serie.\n",
    "\n",
    "### Extensiones y variantes\n",
    "\n",
    "- **ARIMA**: incorpora diferencias entre valores para eliminar tendencias constantes.\n",
    "- **SARIMA**: a√±ade componentes estacionales al modelo ARIMA.\n",
    "- **ARMAX**: a√±ade **variables ex√≥genas** (externas a la serie).  \n",
    "  Combinaciones comunes:\n",
    "  - **ARIMAX**\n",
    "  - **SARIMAX**\n",
    "\n",
    "- **NARX**: versi√≥n **no lineal** de ARX.  \n",
    "  Aunque m√°s complejos de ajustar e interpretar, son m√°s potentes en modelizaci√≥n.\n",
    "\n",
    "- **ARCH (Autoregressive Conditional Heteroskedasticity)**:  \n",
    "  Dise√±ado para series con cambios abruptos y no estacionarios, como las econ√≥micas.\n",
    "\n",
    "- **GARCH (Generalized ARCH)**:  \n",
    "  Extiende ARCH para capturar patrones m√°s complejos de heterocedasticidad condicional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales en Series Temporales: TDNN\n",
    "\n",
    "Una forma directa de aplicar un modelo neuronal a problemas de series temporales es utilizar como **entradas**:\n",
    "\n",
    "- Los valores actuales de la serie.\n",
    "- Valores anteriores (retardos).\n",
    "- Otras variables adicionales que se quieran considerar.\n",
    "\n",
    "Esta estructura se conoce como **TDNN (Time Delay Neural Network)**.\n",
    "\n",
    "### Esquema conceptual de una TDNN\n",
    "\n",
    "La red TDNN est√° compuesta por capas ocultas que reciben entradas retardadas de la serie \\( x \\), junto con otras entradas relevantes \\( e \\). La salida puede representar una **predicci√≥n futura** de la serie, por ejemplo \\( \\hat{y}_{t+p} \\), siendo \\( p \\) el horizonte de predicci√≥n.\n",
    "\n",
    "```text\n",
    "Entradas: x(t), x(t-1), ..., x(t-n), e(t)\n",
    "           ‚îÇ\n",
    "           ‚ñº\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ Capa oculta 1 ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "           ‚îÇ\n",
    "           ‚ñº\n",
    "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "    ‚îÇ Capa oculta 2 ‚îÇ\n",
    "    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "           ‚îÇ\n",
    "           ‚ñº\n",
    "      Predicci√≥n: ≈∑(t+p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales Recurrentes (RNN)\n",
    "\n",
    "Las **Redes Neuronales Recurrentes** (RNN) son una clase de redes dise√±adas para procesar datos secuenciales, como las series temporales. La caracter√≠stica principal de estas redes es que **mantienen una memoria** de valores anteriores al actual, permitiendo modelar dependencias temporales.\n",
    "\n",
    "### ¬øC√≥mo funcionan?\n",
    "\n",
    "Una RNN tiene una estructura similar a una red densa:  \n",
    "- Cada valor de la serie pasa por una neurona distinta.\n",
    "- Cada neurona aplica un conjunto de pesos.\n",
    "\n",
    "Sin embargo, **a diferencia de una red densa**, en una RNN:\n",
    "- El resultado de cada neurona se utiliza tambi√©n en la siguiente neurona.\n",
    "- Es decir, **se transmite informaci√≥n desde los pasos anteriores a los siguientes**.\n",
    "\n",
    "### Ejemplo de funcionamiento\n",
    "\n",
    "Dada una serie temporal \\( \\{x_0, x_1, \\dots, x_t\\} \\), donde \\( x_i \\) es el valor en la posici√≥n \\( i \\):\n",
    "\n",
    "- El primer elemento \\( x_0 \\) pasa por la primera neurona y se transforma en una salida \\( y_0 \\) tras aplicar pesos y sesgo.\n",
    "- Para el segundo elemento, la neurona calcula \\( y_1 \\) usando:\n",
    "  - \\( x_1 \\): la entrada actual.\n",
    "  - \\( y_0 \\): el resultado de la celda anterior.\n",
    "\n",
    "Este patr√≥n se repite para todos los pasos de la secuencia, haciendo que las neuronas **compartan informaci√≥n secuencialmente**.\n",
    "\n",
    "> Figura 4.11: Representaci√≥n de una RNN. A la izquierda, una vista \"enrollada\"; a la derecha, la versi√≥n \"desplegada\" que muestra el flujo de datos paso a paso.\n",
    "\n",
    "### Representaci√≥n matem√°tica\n",
    "\n",
    "El funcionamiento interno de una neurona en una RNN se puede expresar como:\n",
    "\n",
    "```math\n",
    "Y_t = f(W \\cdot X_t + U \\cdot Y_{t-1} + b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde:\n",
    "\n",
    "    W: pesos para la entrada actual XtXt‚Äã\n",
    "\n",
    "    U: pesos para la salida anterior Yt‚àí1Yt‚àí1‚Äã\n",
    "\n",
    "    b: sesgo\n",
    "\n",
    "    f: funci√≥n de activaci√≥n (como tanh o ReLU)\n",
    "\n",
    "Puntos clave sobre las RNN\n",
    "\n",
    "    Memoria contextual\n",
    "    La red aprende a mantener y transportar informaci√≥n √∫til a lo largo del tiempo para capturar el contexto temporal.\n",
    "\n",
    "    Salida de la red\n",
    "    El resultado final suele ser el estado de la √∫ltima celda YfinalYfinal‚Äã, que se compara con el valor real para calcular la p√©rdida y retropropagar el error.\n",
    "\n",
    "    Salidas intermedias\n",
    "    En algunos casos, se pueden usar todas las salidas intermedias de la red:\n",
    "    {Y0,Y1,‚Ä¶,Yt}{Y0‚Äã,Y1‚Äã,‚Ä¶,Yt‚Äã}, aunque esto es menos com√∫n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparaci√≥n de datos para una RNN\n",
    "\n",
    "Para usar correctamente una **Red Neuronal Recurrente (RNN)**, las entradas deben tener una estructura secuencial o depender del tiempo.\n",
    "\n",
    "### Formato de entrada\n",
    "\n",
    "Una entrada t√≠pica en una RNN tiene **3 dimensiones**:\n",
    "\n",
    "(n, t, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Donde:\n",
    "- `n`: n√∫mero de muestras.\n",
    "- `t`: n√∫mero de pasos temporales (longitud de la serie).\n",
    "- `f`: n√∫mero de caracter√≠sticas por paso temporal.\n",
    "\n",
    "> - Para series univariantes: `f = 1`  \n",
    "> - Para series multivariantes: `f > 1`\n",
    "\n",
    "La salida de la red tendr√° la forma:\n",
    "\n",
    "(n, f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Donde `f'` puede representar, por ejemplo, el n√∫mero de pasos futuros a predecir.\n",
    "\n",
    "---\n",
    "\n",
    "## Transformaci√≥n supervisada mediante \"enventanado\"\n",
    "\n",
    "Dado que queremos **predecir valores futuros** a partir de valores pasados, el problema se transforma en un problema de **aprendizaje supervisado** usando un proceso llamado **enventanado de datos**.\n",
    "\n",
    "### ¬øQu√© es el enventanado?\n",
    "\n",
    "Consiste en tomar ventanas deslizantes de la serie temporal para generar pares de entrada/salida.\n",
    "\n",
    "### Procedimiento paso a paso\n",
    "\n",
    "1. **Elegir un tama√±o de ventana** \\( w \\): n√∫mero de pasos del pasado que se usar√°n como entrada.\n",
    "2. **Crear la primera ventana**:  \n",
    "   Tomar los primeros \\( w \\) elementos de la serie:  \n",
    "   \\[\n",
    "   \\text{Entrada} = [x_0, x_1, ..., x_{w-1}]\n",
    "   \\]  \n",
    "   La **etiqueta (output)** asociada ser√°:  \n",
    "   \\[\n",
    "   x_w\n",
    "   \\]\n",
    "3. **Desplazar la ventana una posici√≥n** y repetir:  \n",
    "   \\[\n",
    "   \\text{Entrada} = [x_1, ..., x_w], \\quad \\text{Etiqueta} = x_{w+1}\n",
    "   \\]\n",
    "4. **Repetir hasta el final de la serie**.  \n",
    "   Para una serie temporal de longitud \\( T \\), se generar√°n:\n",
    "   \\[\n",
    "   T - w - 1 \\quad \\text{ventanas}\n",
    "   \\]\n",
    "\n",
    "> Este proceso convierte una √∫nica serie temporal en un conjunto de muestras supervisadas listas para entrenar la RNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/rnn.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma manera que en el resto de los problemas vistos anteriormente, es conveniente dividir la totalidad de los datos de los que se dispone en conjuntos de entrenamiento, validaci√≥n y test. Sin embargo, los datos temporales tienen la caracter√≠stica de que el orden importa, por lo que no se pueden dividir de forma arbitraria. Los datos temporales han de dividirse en conjuntos ordenados en 3\n",
    "fragmentos de tiempo. El tama√±o de cada uno de los fragmentos ser√° equivalente al porcentaje de datos que se destinar√°n a entrenamiento, validaci√≥n y test. Esta divisi√≥n ha de ser previa al proceso de enventanado descrito anteriormente, ya que, si el corte se hace con la serie temporal original va a producirse una transferencia de informaci√≥n entre los conjuntos de datos. Por ejemplo, se puede tener que datos de las ventanas finales del conjunto de entrenamiento tambi√©n aparecer√°n en el conjunto de\n",
    "validaci√≥n y lo mismo ocurrir√° con el conjunto de validaci√≥n y de test. Destacar que estos fragmentos no hace falta que sigan ning√∫n orden concreto. Incluso se puede intercalar el conjunto de test en el interior del conjunto de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/split.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation en redes neuronales\n",
    "\n",
    "En una red neuronal tradicional (MLP o convolucional):\n",
    "\n",
    "- La **informaci√≥n fluye de forma secuencial** entre las capas.\n",
    "- No hay **realimentaci√≥n** entre capas o neuronas.\n",
    "- Durante la retropropagaci√≥n, el flujo de informaci√≥n se invierte:  \n",
    "  desde la **√∫ltima capa** hacia la **primera capa**.\n",
    "\n",
    "---\n",
    "\n",
    "## Retropropagaci√≥n en redes recurrentes\n",
    "\n",
    "En una **Red Neuronal Recurrente (RNN)**:\n",
    "\n",
    "- La informaci√≥n se transmite no solo entre capas, sino tambi√©n **entre neuronas dentro de una misma capa**, a lo largo del tiempo.\n",
    "- Esto genera una **mayor cantidad de operaciones** para calcular la salida.\n",
    "\n",
    "El algoritmo de aprendizaje en RNN se llama:\n",
    "\n",
    "### üîÑ Backpropagation Through Time (BTT)\n",
    "\n",
    "Este algoritmo extiende la retropropagaci√≥n tradicional para tener en cuenta las **realimentaciones** temporales entre neuronas.\n",
    "\n",
    "---\n",
    "\n",
    "### üß± Problemas del BTT\n",
    "\n",
    "1. **Olvido de largo plazo**:\n",
    "   - Si los pesos que transmiten la informaci√≥n entre celdas son peque√±os, la informaci√≥n se **desvanece** al recorrer muchas celdas.\n",
    "   - Esto impide que la red recuerde eventos **lejanos en el tiempo**.\n",
    "\n",
    "2. **Desvanecimiento/explosi√≥n del gradiente**:\n",
    "   - Debido al gran n√∫mero de operaciones acumuladas, los **gradientes pueden desaparecer** (hacerse muy peque√±os) o **explotar** (hacerse muy grandes).\n",
    "   - Esto **dificulta el entrenamiento** de la red.\n",
    "\n",
    "---\n",
    "\n",
    "## Soluciones: GRU y LSTM\n",
    "\n",
    "Para solventar estos problemas se han desarrollado variantes de RNN como:\n",
    "\n",
    "- **GRU** (Gated Recurrent Unit)\n",
    "- **LSTM** (Long Short-Term Memory)\n",
    "\n",
    "Ambas:\n",
    "\n",
    "- Introducen **mecanismos de control (puertas)** que regulan el paso y almacenamiento de informaci√≥n.\n",
    "- Son capaces de **recordar informaci√≥n relevante a largo plazo**.\n",
    "- **Mitigan el desvanecimiento del gradiente**, mejorando el proceso de aprendizaje.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
