{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introducción a las series temporales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesar correctamente diferentes tipos de datos requiere de transformaciones matemáticas concretas\n",
    "(por ejemplo, transformar una característica categórica en one-hot-encoding) o estructuras de redes especiales (por ejemplo, redes convolucionales para procesar imágenes) para poder tener en cuenta aquellas características concretas que tienen esas estructuras de datos. De forma análoga, parece interesante pensar que un estudio acerca de qué son los datos de naturaleza secuencial puede llevar a proporcionar la intuición sobre la forma en que se debería estructurar una red que sea capaz de\n",
    "extraer información de este tipo de datos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí hay que partir de lo que se considera una serie temporal; cualquier dato que haya sido recogido en intervalos de tiempo constituye una serie temporal. Es un conjunto de observaciones donde la relación de obtención de cada punto importa y puede aportar mucha información del fenómeno\n",
    "que se intenta resolver. Cambiar su orden cambiaría el significado de los datos y, por tanto, sería una fuente de ruido para los modelos. Un ejemplo de serie temporal puede ser el ejemplo que se muestra a continuación: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ejemplo de serie temporal, coches vendidos por mes en un concesionario, entre enero de\n",
    "2018 y enero de 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/sales.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, hay una variable dependiente del tiempo que va desde enero de 2018 hasta diciembre de 2020 con frecuencia mensual. Para cada mes, se tiene el número de coches vendidos y hay, por tanto, un total de 36 valores en la serie temporal. \n",
    "\n",
    "El ejemplo es un caso de serie temporal univariante. Si hubiera múltiples variables\n",
    "dependientes del tiempo (por ejemplo, las ventas de coches en los concesionarios de\n",
    "la ciudad) se estaría hablando de serie temporal multivariante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/sales-multivariante.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis de series temporales tiene una enorme aplicabilidad en múltiples disciplinas científicas:\n",
    "\n",
    "- **Economía**: análisis de precios y demandas.\n",
    "- **Marketing**: seguimiento de ventas y evolución de productos.\n",
    "- **Medicina**: análisis de bioseñales (ECG, EEG, EOG) y datos clínicos como:\n",
    "  - Número de pacientes en urgencias.\n",
    "  - Demanda de especialistas.\n",
    "  - Llamadas a servicios de emergencia (112).\n",
    "\n",
    "- **Meteorología/Climatología**: análisis y predicción de fenómenos climáticos, especialmente relevantes por el cambio climático.\n",
    "- **IoT (Internet of Things)**: análisis de datos capturados por sensores en procesos, personas o dispositivos.\n",
    "\n",
    "## Series Temporales y Datos Secuenciales\n",
    "\n",
    "Más allá de las series temporales clásicas, existen datos secuenciales que también pueden ser tratados con técnicas similares:\n",
    "\n",
    "- **Lenguaje natural (NLP)**:\n",
    "  - Predicción de palabras.\n",
    "  - Resumen y traducción de textos.\n",
    "  - Generación de imágenes a partir de texto.\n",
    "\n",
    "- **Sonido**:\n",
    "  - Identificación de género musical.\n",
    "  - Comparación entre canciones.\n",
    "  - Transcripción de voz a texto.\n",
    "  - Generación de imágenes desde sonido.\n",
    "\n",
    "> Se recomienda consultar bibliografía especializada en NLP para un tratamiento más profundo de estos temas.\n",
    "\n",
    "## Preprocesamiento de Datos\n",
    "\n",
    "El éxito de un modelo de aprendizaje profundo depende en gran medida del procesamiento adecuado de los datos. Para ello, es esencial comprender propiedades clave de las series temporales como:\n",
    "\n",
    "- **Tendencia**\n",
    "- **Estacionalidad**\n",
    "- **Estacionariedad**\n",
    "\n",
    "Estas propiedades serán introducidas en este capítulo para mejorar la preparación de datos antes del modelado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tendencia: Es un comportamiento que muestra el desplazamiento lineal de los valores de la serie temporal sobre un gran periodo de tiempo. Dicho de otra forma, se observa una tendencia cuando hay un comportamiento lineal que puede tener una pendiente positiva o negativa dentro de la serie\n",
    "temporal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/tendencia.png\" alt=\"Total de coches vendidos\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La tendencia no tiene por qué ser constante en una serie temporal: puede cambiar de creciente a decreciente, o puede incluso cambiar su pendiente según va avanzando el tiempo. Existe incluso la posibilidad de que no aparezca una tendencia clara en la serie temporal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X_t = \\frac{1}{N} \\sum_{k=0}^{N-1} X_{t-k}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La media móvil permite eliminar pequeñas oscilaciones obteniendo la tendencia de la serie temporal en cada punto. La serie temporal obtenida es menos sensible a las vibraciones de alta frecuencia, centrándose en los comportamientos a largo plazo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/media.png\" alt=\"Total de coches vendidos\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El cálculo de la media móvil depende del parámetro N; este parámetro determina las frecuencias de las oscilaciones de alta frecuencia que son eliminadas/amortiguadas. Se puede demostrar que esta operación de promediado actúa como un filtro pasa-baja, sistema que deja pasar las bajas frecuencias y elimina las altas. A mayor valor de N, más datos se cogen para el cálculo de la media y una mayor cantidad de altas frecuencias son eliminadas. En la práctica, es interesante escoger un valor de N que permita eliminar el ruido a corto plazo, pero no tan grande como para obviar los movimientos de la tendencia que, precisamente, se quieren obtener con la media móvil; aquí el conocimiento del experto en\n",
    "el problema es fundamental."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/medias.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estacionalidad. Es una característica de las series temporales en la que los datos experimentan cambios regulares y predecibles con una frecuencia constante. Esta frecuencia puede ser, por ejemplo, diaria, semanal o mensual.\n",
    "\n",
    "Cualquier fluctuación predecible de frecuencia constante que aparezca en una serie temporal se dice que es estacional. \n",
    "\n",
    "Aparece de forma natural en muchos procesos medidos. El consumo eléctrico en una casa presenta una frecuencia estacional diaria (cuando estamos durmiendo, no se consume electricidad, por ejemplo). Además, el consumo eléctrico crece en las épocas frías como otoño e invierno, por lo que se aprecia también una estacionalidad de frecuencia anual. Otro ejemplo son las ventas de productos por internet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/estacionalidad.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la figura (A), se puede observar que la gente tiende a comprar más productos en las cercanías del fin de semana: se puede apreciar gráficamente la estacionalidad semanal. En la figura (B) se representa la misma cantidad que en la gráfica superior, pero en un intervalo temporal anterior. Este intervalo temporal coincidió con una campaña de marketing agresiva que popularizó la tienda e hizo que las ventas crecieran mucho. Las dos series temporales presentan la misma estacionalidad, a pesar de que sus valores máximos y mínimos en distintos puntos sean tan distintos. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uno de los métodos utilizados comúnmente para cuantificar esta estacionalidad de forma matemática es usar la operación de diferenciación. Consiste en obtener una nueva serie temporal a partir de la original calculando diferencias de valores en diferentes instantes de tiempo. La diferenciación\n",
    "de primer orden de una serie temporal sería la siguiente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X^1_t = X_t - X_{t-1}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la nueva serie temporal diferenciada tendría una entrada menos que la serie temporal original. La diferenciación necesaria para eliminar la tendencia estacional es la diferenciación estacional. Se calcula aplicando la diferencia entre la observación y la observación anterior en\n",
    "la misma posición de la estación. Por ejemplo, en el ejemplo descrito anteriormente, la diferencia estacional del día jueves 28/02 se calcularía restando el valor original del jueves 28/02 con el valor del jueves anterior, 21/02, expresado matemáticamente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "X^1_t = X_t - X_{t-p}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde pes el periodo estacional, en el ejemplo descrito anteriormente,p = 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/desestacional.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estacionariedad. Una serie temporal es estacionaria si su media y su desviación estándar se mantienen constantes en el tiempo. Gráficamente, esto se puede apreciar cuando los valores de la serie oscilan alrededor de una media constante y la variabilidad con respecto a esa media\n",
    "también permanece constante en el tiempo. Las series que presenten una tendencia o una estacionalidad no son estacionarias, pero se pueden utilizar los métodos descritos anteriormente para intentar transformar una serie en estacionaria. Existe la posibilidad de que simplemente con estos\n",
    "métodos no se pueda transformar la serie en estacionaria y haga falta\n",
    "echar mano de otros métodos,(que sucede con las redes recurrentes aquí??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez vistas las características básicas de una serie temporal, haremos un rápido repaso a los métodos clásicos antes de explicar los basados en Aprendizaje Profundo.\n",
    "\n",
    "Existe un gran número de modelos utilizados para modelizar y realizar predicciones en series temporales. Estos modelos tienen como característica general su **linealidad**, es decir, presentan dependencia lineal con errores pasados y/o con valores anteriores de la serie.\n",
    "\n",
    "### Tipos de modelos clásicos\n",
    "\n",
    "- **MA (Moving Average)**: modelos que consideran los errores pasados.\n",
    "- **AR (Autoregressive)**: modelos que consideran valores anteriores de la serie.\n",
    "- **ARMA**: combinación de AR y MA.  \n",
    "  Son modelos **flexibles**, ya que el número de entradas/salidas se puede ajustar según el problema.\n",
    "\n",
    "Los **parámetros**, principalmente el orden del modelo, se pueden estimar mediante la **autocorrelación** y la **correlación parcial** de la serie.\n",
    "\n",
    "### Extensiones y variantes\n",
    "\n",
    "- **ARIMA**: incorpora diferencias entre valores para eliminar tendencias constantes.\n",
    "- **SARIMA**: añade componentes estacionales al modelo ARIMA.\n",
    "- **ARMAX**: añade **variables exógenas** (externas a la serie).  \n",
    "  Combinaciones comunes:\n",
    "  - **ARIMAX**\n",
    "  - **SARIMAX**\n",
    "\n",
    "- **NARX**: versión **no lineal** de ARX.  \n",
    "  Aunque más complejos de ajustar e interpretar, son más potentes en modelización.\n",
    "\n",
    "- **ARCH (Autoregressive Conditional Heteroskedasticity)**:  \n",
    "  Diseñado para series con cambios abruptos y no estacionarios, como las económicas.\n",
    "\n",
    "- **GARCH (Generalized ARCH)**:  \n",
    "  Extiende ARCH para capturar patrones más complejos de heterocedasticidad condicional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales en Series Temporales: TDNN\n",
    "\n",
    "Una forma directa de aplicar un modelo neuronal a problemas de series temporales es utilizar como **entradas**:\n",
    "\n",
    "- Los valores actuales de la serie.\n",
    "- Valores anteriores (retardos).\n",
    "- Otras variables adicionales que se quieran considerar.\n",
    "\n",
    "Esta estructura se conoce como **TDNN (Time Delay Neural Network)**.\n",
    "\n",
    "### Esquema conceptual de una TDNN\n",
    "\n",
    "La red TDNN está compuesta por capas ocultas que reciben entradas retardadas de la serie \\( x \\), junto con otras entradas relevantes \\( e \\). La salida puede representar una **predicción futura** de la serie, por ejemplo \\( \\hat{y}_{t+p} \\), siendo \\( p \\) el horizonte de predicción.\n",
    "\n",
    "```text\n",
    "Entradas: x(t), x(t-1), ..., x(t-n), e(t)\n",
    "           │\n",
    "           ▼\n",
    "    ┌─────────────┐\n",
    "    │ Capa oculta 1 │\n",
    "    └─────────────┘\n",
    "           │\n",
    "           ▼\n",
    "    ┌─────────────┐\n",
    "    │ Capa oculta 2 │\n",
    "    └─────────────┘\n",
    "           │\n",
    "           ▼\n",
    "      Predicción: ŷ(t+p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redes Neuronales Recurrentes (RNN)\n",
    "\n",
    "Las **Redes Neuronales Recurrentes** (RNN) son una clase de redes diseñadas para procesar datos secuenciales, como las series temporales. La característica principal de estas redes es que **mantienen una memoria** de valores anteriores al actual, permitiendo modelar dependencias temporales.\n",
    "\n",
    "### ¿Cómo funcionan?\n",
    "\n",
    "Una RNN tiene una estructura similar a una red densa:  \n",
    "- Cada valor de la serie pasa por una neurona distinta.\n",
    "- Cada neurona aplica un conjunto de pesos.\n",
    "\n",
    "Sin embargo, **a diferencia de una red densa**, en una RNN:\n",
    "- El resultado de cada neurona se utiliza también en la siguiente neurona.\n",
    "- Es decir, **se transmite información desde los pasos anteriores a los siguientes**.\n",
    "\n",
    "### Ejemplo de funcionamiento\n",
    "\n",
    "Dada una serie temporal \\( \\{x_0, x_1, \\dots, x_t\\} \\), donde \\( x_i \\) es el valor en la posición \\( i \\):\n",
    "\n",
    "- El primer elemento \\( x_0 \\) pasa por la primera neurona y se transforma en una salida \\( y_0 \\) tras aplicar pesos y sesgo.\n",
    "- Para el segundo elemento, la neurona calcula \\( y_1 \\) usando:\n",
    "  - \\( x_1 \\): la entrada actual.\n",
    "  - \\( y_0 \\): el resultado de la celda anterior.\n",
    "\n",
    "Este patrón se repite para todos los pasos de la secuencia, haciendo que las neuronas **compartan información secuencialmente**.\n",
    "\n",
    "> Figura 4.11: Representación de una RNN. A la izquierda, una vista \"enrollada\"; a la derecha, la versión \"desplegada\" que muestra el flujo de datos paso a paso.\n",
    "\n",
    "### Representación matemática\n",
    "\n",
    "El funcionamiento interno de una neurona en una RNN se puede expresar como:\n",
    "\n",
    "```math\n",
    "Y_t = f(W \\cdot X_t + U \\cdot Y_{t-1} + b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Donde:\n",
    "\n",
    "    W: pesos para la entrada actual XtXt​\n",
    "\n",
    "    U: pesos para la salida anterior Yt−1Yt−1​\n",
    "\n",
    "    b: sesgo\n",
    "\n",
    "    f: función de activación (como tanh o ReLU)\n",
    "\n",
    "Puntos clave sobre las RNN\n",
    "\n",
    "    Memoria contextual\n",
    "    La red aprende a mantener y transportar información útil a lo largo del tiempo para capturar el contexto temporal.\n",
    "\n",
    "    Salida de la red\n",
    "    El resultado final suele ser el estado de la última celda YfinalYfinal​, que se compara con el valor real para calcular la pérdida y retropropagar el error.\n",
    "\n",
    "    Salidas intermedias\n",
    "    En algunos casos, se pueden usar todas las salidas intermedias de la red:\n",
    "    {Y0,Y1,…,Yt}{Y0​,Y1​,…,Yt​}, aunque esto es menos común."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparación de datos para una RNN\n",
    "\n",
    "Para usar correctamente una **Red Neuronal Recurrente (RNN)**, las entradas deben tener una estructura secuencial o depender del tiempo.\n",
    "\n",
    "### Formato de entrada\n",
    "\n",
    "Una entrada típica en una RNN tiene **3 dimensiones**:\n",
    "\n",
    "(n, t, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Donde:\n",
    "- `n`: número de muestras.\n",
    "- `t`: número de pasos temporales (longitud de la serie).\n",
    "- `f`: número de características por paso temporal.\n",
    "\n",
    "> - Para series univariantes: `f = 1`  \n",
    "> - Para series multivariantes: `f > 1`\n",
    "\n",
    "La salida de la red tendrá la forma:\n",
    "\n",
    "(n, f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Donde `f'` puede representar, por ejemplo, el número de pasos futuros a predecir.\n",
    "\n",
    "---\n",
    "\n",
    "## Transformación supervisada mediante \"enventanado\"\n",
    "\n",
    "Dado que queremos **predecir valores futuros** a partir de valores pasados, el problema se transforma en un problema de **aprendizaje supervisado** usando un proceso llamado **enventanado de datos**.\n",
    "\n",
    "### ¿Qué es el enventanado?\n",
    "\n",
    "Consiste en tomar ventanas deslizantes de la serie temporal para generar pares de entrada/salida.\n",
    "\n",
    "### Procedimiento paso a paso\n",
    "\n",
    "1. **Elegir un tamaño de ventana** \\( w \\): número de pasos del pasado que se usarán como entrada.\n",
    "2. **Crear la primera ventana**:  \n",
    "   Tomar los primeros \\( w \\) elementos de la serie:  \n",
    "   \\[\n",
    "   \\text{Entrada} = [x_0, x_1, ..., x_{w-1}]\n",
    "   \\]  \n",
    "   La **etiqueta (output)** asociada será:  \n",
    "   \\[\n",
    "   x_w\n",
    "   \\]\n",
    "3. **Desplazar la ventana una posición** y repetir:  \n",
    "   \\[\n",
    "   \\text{Entrada} = [x_1, ..., x_w], \\quad \\text{Etiqueta} = x_{w+1}\n",
    "   \\]\n",
    "4. **Repetir hasta el final de la serie**.  \n",
    "   Para una serie temporal de longitud \\( T \\), se generarán:\n",
    "   \\[\n",
    "   T - w - 1 \\quad \\text{ventanas}\n",
    "   \\]\n",
    "\n",
    "> Este proceso convierte una única serie temporal en un conjunto de muestras supervisadas listas para entrenar la RNN.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/rnn.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De la misma manera que en el resto de los problemas vistos anteriormente, es conveniente dividir la totalidad de los datos de los que se dispone en conjuntos de entrenamiento, validación y test. Sin embargo, los datos temporales tienen la característica de que el orden importa, por lo que no se pueden dividir de forma arbitraria. Los datos temporales han de dividirse en conjuntos ordenados en 3\n",
    "fragmentos de tiempo. El tamaño de cada uno de los fragmentos será equivalente al porcentaje de datos que se destinarán a entrenamiento, validación y test. Esta división ha de ser previa al proceso de enventanado descrito anteriormente, ya que, si el corte se hace con la serie temporal original va a producirse una transferencia de información entre los conjuntos de datos. Por ejemplo, se puede tener que datos de las ventanas finales del conjunto de entrenamiento también aparecerán en el conjunto de\n",
    "validación y lo mismo ocurrirá con el conjunto de validación y de test. Destacar que estos fragmentos no hace falta que sigan ningún orden concreto. Incluso se puede intercalar el conjunto de test en el interior del conjunto de entrenamiento. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figs/split.png\" alt=\"Total de coches vendidos\" width=\"60%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation en redes neuronales\n",
    "\n",
    "En una red neuronal tradicional (MLP o convolucional):\n",
    "\n",
    "- La **información fluye de forma secuencial** entre las capas.\n",
    "- No hay **realimentación** entre capas o neuronas.\n",
    "- Durante la retropropagación, el flujo de información se invierte:  \n",
    "  desde la **última capa** hacia la **primera capa**.\n",
    "\n",
    "---\n",
    "\n",
    "## Retropropagación en redes recurrentes\n",
    "\n",
    "En una **Red Neuronal Recurrente (RNN)**:\n",
    "\n",
    "- La información se transmite no solo entre capas, sino también **entre neuronas dentro de una misma capa**, a lo largo del tiempo.\n",
    "- Esto genera una **mayor cantidad de operaciones** para calcular la salida.\n",
    "\n",
    "El algoritmo de aprendizaje en RNN se llama:\n",
    "\n",
    "### 🔄 Backpropagation Through Time (BTT)\n",
    "\n",
    "Este algoritmo extiende la retropropagación tradicional para tener en cuenta las **realimentaciones** temporales entre neuronas.\n",
    "\n",
    "---\n",
    "\n",
    "### 🧱 Problemas del BTT\n",
    "\n",
    "1. **Olvido de largo plazo**:\n",
    "   - Si los pesos que transmiten la información entre celdas son pequeños, la información se **desvanece** al recorrer muchas celdas.\n",
    "   - Esto impide que la red recuerde eventos **lejanos en el tiempo**.\n",
    "\n",
    "2. **Desvanecimiento/explosión del gradiente**:\n",
    "   - Debido al gran número de operaciones acumuladas, los **gradientes pueden desaparecer** (hacerse muy pequeños) o **explotar** (hacerse muy grandes).\n",
    "   - Esto **dificulta el entrenamiento** de la red.\n",
    "\n",
    "---\n",
    "\n",
    "## Soluciones: GRU y LSTM\n",
    "\n",
    "Para solventar estos problemas se han desarrollado variantes de RNN como:\n",
    "\n",
    "- **GRU** (Gated Recurrent Unit)\n",
    "- **LSTM** (Long Short-Term Memory)\n",
    "\n",
    "Ambas:\n",
    "\n",
    "- Introducen **mecanismos de control (puertas)** que regulan el paso y almacenamiento de información.\n",
    "- Son capaces de **recordar información relevante a largo plazo**.\n",
    "- **Mitigan el desvanecimiento del gradiente**, mejorando el proceso de aprendizaje.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
